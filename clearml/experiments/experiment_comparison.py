#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ ClearML —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from clearml import Task

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.style.use("default")
sns.set_palette("husl")


class ExperimentComparison:
    """–°–∏—Å—Ç–µ–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ ClearML."""

    def __init__(self, project_name: str = "ResearchHub"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.

        Args:
            project_name: –ò–º—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ ClearML
        """
        self.project_name = project_name
        self.experiments_data = []
        logger.info(
            f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {project_name}"
        )

    def collect_experiments_data(
        self,
        task_ids: list[str] | None = None,
        experiment_names: list[str] | None = None,
        limit: int = 20,
    ) -> list[dict[str, Any]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏–∑ ClearML.

        Args:
            task_ids: –°–ø–∏—Å–æ–∫ ID –∑–∞–¥–∞—á (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã)
            experiment_names: –§–∏–ª—å—Ç—Ä –ø–æ –∏–º–µ–Ω–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        """
        try:
            experiments = []

            if task_ids:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø–æ ID
                for task_id in task_ids:
                    try:
                        task = Task.get_task(task_id=task_id)
                        exp_data = self._extract_experiment_data(task)
                        if exp_data:
                            experiments.append(exp_data)
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–¥–∞—á—É {task_id}: {e}")
            else:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
                tasks = Task.get_tasks(
                    project_name=self.project_name,
                    task_filter={"status": ["completed"]},
                    order_by=["-created"],
                )[:limit]

                for task in tasks:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∞–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
                    if experiment_names and not any(
                        name in task.name for name in experiment_names
                    ):
                        continue

                    exp_data = self._extract_experiment_data(task)
                    if exp_data:
                        experiments.append(exp_data)

            self.experiments_data = experiments
            logger.info(f"–°–æ–±—Ä–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ {len(experiments)} —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º")

            return experiments

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {e}")
            return []

    def _extract_experiment_data(self, task: Task) -> dict[str, Any] | None:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.

        Args:
            task: ClearML –∑–∞–¥–∞—á–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        """
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            experiment_data = {
                "task_id": task.id,
                "name": task.name,
                "created": task.data.created,
                "completed": task.data.completed,
                "status": task.get_status(),
                "runtime": None,
                "metrics": {},
                "parameters": {},
                "artifacts": [],
            }

            # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            if task.data.created and task.data.completed:
                runtime = task.data.completed - task.data.created
                experiment_data["runtime"] = runtime.total_seconds()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            try:
                params = task.get_parameters()
                experiment_data["parameters"] = params
            except Exception:
                pass

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            try:
                scalars = task.get_reported_scalars()
                metrics = {}

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
                for title, series_dict in scalars.items():
                    for series, data in series_dict.items():
                        if data.get("y"):
                            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                            final_value = data["y"][-1]
                            metric_key = (
                                f"{title}_{series}" if title != series else series
                            )
                            metrics[metric_key] = float(final_value)

                experiment_data["metrics"] = metrics
            except Exception:
                pass

            # –°–ø–∏—Å–æ–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
            try:
                artifacts = task.artifacts
                experiment_data["artifacts"] = (
                    list(artifacts.keys()) if artifacts else []
                )
            except Exception:
                pass

            return experiment_data

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∑–∞–¥–∞—á–∏ {task.id}: {e}")
            return None

    def create_metrics_comparison_table(self) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

        Returns:
            DataFrame —Å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫
        """
        if not self.experiments_data:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            return pd.DataFrame()

        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
            rows = []
            for exp in self.experiments_data:
                row = {
                    "Experiment": exp["name"][:50] + "..."
                    if len(exp["name"]) > 50
                    else exp["name"],
                    "Task_ID": exp["task_id"][:8] + "...",
                    "Status": exp["status"],
                    "Runtime_min": round(exp["runtime"] / 60, 2)
                    if exp["runtime"]
                    else None,
                    "Created": exp["created"].strftime("%Y-%m-%d %H:%M")
                    if exp["created"]
                    else None,
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                for metric_name, value in exp["metrics"].items():
                    if isinstance(value, int | float):
                        row[metric_name] = round(float(value), 4)

                rows.append(row)

            df = pd.DataFrame(rows)

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ª—É—á—à–µ–π –º–µ—Ç—Ä–∏–∫–µ (–µ—Å–ª–∏ –µ—Å—Ç—å accuracy)
            if "test_accuracy" in df.columns:
                df = df.sort_values("test_accuracy", ascending=False)
            elif "Test Metrics_accuracy" in df.columns:
                df = df.sort_values("Test Metrics_accuracy", ascending=False)
            elif any("accuracy" in col for col in df.columns):
                accuracy_col = next(
                    col for col in df.columns if "accuracy" in col.lower()
                )
                df = df.sort_values(accuracy_col, ascending=False)

            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å {len(df)} —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏")
            return df

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}")
            return pd.DataFrame()

    def plot_metrics_comparison(
        self, metrics_to_compare: list[str] = None, save_path: str = None
    ) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.

        Args:
            metrics_to_compare: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –≥—Ä–∞—Ñ–∏–∫—É
        """
        if not self.experiments_data:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return ""

        try:
            df = self.create_metrics_comparison_table()
            if df.empty:
                return ""

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            if metrics_to_compare is None:
                numeric_columns = df.select_dtypes(include=[np.number]).columns
                metrics_to_compare = [
                    col
                    for col in numeric_columns
                    if col not in ["Runtime_min"] and "accuracy" in col.lower()
                ][:4]

            if not metrics_to_compare:
                metrics_to_compare = df.select_dtypes(include=[np.number]).columns[:4]

            # –°–æ–∑–¥–∞–µ–º subplot –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            axes = axes.flatten()

            for i, metric in enumerate(metrics_to_compare):
                if i >= 4:  # –ú–∞–∫—Å–∏–º—É–º 4 –≥—Ä–∞—Ñ–∏–∫–∞
                    break

                if metric in df.columns:
                    ax = axes[i]

                    # –ë–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    data_to_plot = df.nlargest(10, metric) if len(df) > 10 else df

                    bars = ax.bar(
                        range(len(data_to_plot)),
                        data_to_plot[metric],
                        color=sns.color_palette("husl", len(data_to_plot)),
                    )

                    ax.set_title(
                        f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –º–µ—Ç—Ä–∏–∫–µ: {metric}",
                        fontsize=12,
                        fontweight="bold",
                    )
                    ax.set_xlabel("–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã")
                    ax.set_ylabel(metric)
                    ax.tick_params(axis="x", rotation=45)

                    # –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ –±–∞—Ä–∞—Ö
                    for _, bar in enumerate(bars):
                        height = bar.get_height()
                        if not pd.isna(height):
                            ax.text(
                                bar.get_x() + bar.get_width() / 2.0,
                                height,
                                f"{height:.3f}",
                                ha="center",
                                va="bottom",
                                fontsize=8,
                            )

                    # –ü–æ–¥–ø–∏—Å–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
                    exp_names = [
                        name[:15] + "..." if len(name) > 15 else name
                        for name in data_to_plot["Experiment"]
                    ]
                    ax.set_xticks(range(len(exp_names)))
                    ax.set_xticklabels(exp_names, rotation=45, ha="right")

            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ subplot'—ã
            for i in range(len(metrics_to_compare), 4):
                fig.delaxes(axes[i])

            plt.tight_layout()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            if save_path is None:
                save_path = (
                    f"metrics_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                )

            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            plt.close()

            logger.info(f"–ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
            return save_path

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return ""

    def plot_runtime_analysis(self, save_path: str = None) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

        Args:
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –≥—Ä–∞—Ñ–∏–∫—É
        """
        try:
            df = self.create_metrics_comparison_table()
            if df.empty or "Runtime_min" not in df.columns:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
                return ""

            # –£–±–∏—Ä–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏
            df_runtime = df.dropna(subset=["Runtime_min"])
            if df_runtime.empty:
                logger.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
                return ""

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

            # –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            bars = ax1.bar(
                range(len(df_runtime)),
                df_runtime["Runtime_min"],
                color=sns.color_palette("viridis", len(df_runtime)),
            )
            ax1.set_title("–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (–º–∏–Ω)", fontweight="bold")
            ax1.set_xlabel("–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã")
            ax1.set_ylabel("–í—Ä–µ–º—è (–º–∏–Ω—É—Ç—ã)")

            # –ü–æ–¥–ø–∏—Å–∏
            exp_names = [
                name[:10] + "..." if len(name) > 10 else name
                for name in df_runtime["Experiment"]
            ]
            ax1.set_xticks(range(len(exp_names)))
            ax1.set_xticklabels(exp_names, rotation=45, ha="right")

            # –ó–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –±–∞—Ä–∞—Ö
            for _, bar in enumerate(bars):
                height = bar.get_height()
                ax1.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height,
                    f"{height:.1f}",
                    ha="center",
                    va="bottom",
                    fontsize=8,
                )

            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
            ax2.hist(
                df_runtime["Runtime_min"],
                bins=min(10, len(df_runtime)),
                color="skyblue",
                alpha=0.7,
                edgecolor="black",
            )
            ax2.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", fontweight="bold")
            ax2.set_xlabel("–í—Ä–µ–º—è (–º–∏–Ω—É—Ç—ã)")
            ax2.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
            ax2.grid(True, alpha=0.3)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            mean_time = df_runtime["Runtime_min"].mean()
            median_time = df_runtime["Runtime_min"].median()
            ax2.axvline(
                mean_time,
                color="red",
                linestyle="--",
                label=f"–°—Ä–µ–¥–Ω–µ–µ: {mean_time:.1f} –º–∏–Ω",
            )
            ax2.axvline(
                median_time,
                color="orange",
                linestyle="--",
                label=f"–ú–µ–¥–∏–∞–Ω–∞: {median_time:.1f} –º–∏–Ω",
            )
            ax2.legend()

            plt.tight_layout()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            if save_path is None:
                save_path = (
                    f"runtime_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                )

            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            plt.close()

            logger.info(f"–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
            return save_path

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            return ""

    def create_performance_matrix(self, save_path: str = None) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

        Args:
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –≥—Ä–∞—Ñ–∏–∫—É
        """
        try:
            df = self.create_metrics_comparison_table()
            if df.empty:
                return ""

            # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            performance_cols = [
                col
                for col in df.columns
                if any(
                    keyword in col.lower()
                    for keyword in ["accuracy", "f1", "precision", "recall"]
                )
            ]

            if not performance_cols:
                logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
                return ""

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
            heatmap_data = df[["Experiment"] + performance_cols].set_index("Experiment")
            heatmap_data = heatmap_data.select_dtypes(include=[np.number])

            if heatmap_data.empty:
                logger.warning("–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã")
                return ""

            # –°–æ–∑–¥–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
            plt.figure(figsize=(12, 8))

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª—É—á—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            heatmap_normalized = (heatmap_data - heatmap_data.min()) / (
                heatmap_data.max() - heatmap_data.min()
            )

            sns.heatmap(
                heatmap_normalized,
                annot=heatmap_data,  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                fmt=".3f",
                cmap="RdYlGn",
                cbar_kws={"label": "–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"},
                linewidths=0.5,
            )

            plt.title(
                "–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤",
                fontsize=14,
                fontweight="bold",
            )
            plt.xlabel("–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            plt.ylabel("–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã")
            plt.xticks(rotation=45)
            plt.yticks(rotation=0)

            plt.tight_layout()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            if save_path is None:
                save_path = (
                    f"performance_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                )

            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            plt.close()

            logger.info(f"–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
            return save_path

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return ""

    def generate_comparison_report(self, output_dir: str = "reports") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

        Args:
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞

        Returns:
            –ü—É—Ç—å –∫ HTML –æ—Ç—á–µ—Ç—É
        """
        try:
            Path(output_dir).mkdir(parents=True, exist_ok=True)

            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            metrics_plot = self.plot_metrics_comparison(
                save_path=f"{output_dir}/metrics_comparison.png"
            )
            runtime_plot = self.plot_runtime_analysis(
                save_path=f"{output_dir}/runtime_analysis.png"
            )
            performance_matrix = self.create_performance_matrix(
                save_path=f"{output_dir}/performance_matrix.png"
            )

            # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–∞–Ω–Ω—ã—Ö
            df = self.create_metrics_comparison_table()

            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            stats = self._calculate_comparison_stats()

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –æ—Ç—á–µ—Ç
            html_content = self._generate_html_report(
                df, stats, metrics_plot, runtime_plot, performance_matrix
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            report_path = f"{output_dir}/experiment_comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(html_content)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ JSON
            json_path = f"{output_dir}/comparison_data.json"
            comparison_data = {
                "experiments": self.experiments_data,
                "statistics": stats,
                "generated_at": datetime.now().isoformat(),
            }

            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(comparison_data, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"–û—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            return report_path

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return ""

    def _calculate_comparison_stats(self) -> dict[str, Any]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤."""
        if not self.experiments_data:
            return {}

        stats = {
            "total_experiments": len(self.experiments_data),
            "completed_experiments": len(
                [e for e in self.experiments_data if e["status"] == "completed"]
            ),
            "average_runtime_min": 0,
            "best_experiment": None,
            "metrics_summary": {},
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        runtimes = [e["runtime"] for e in self.experiments_data if e["runtime"]]
        if runtimes:
            stats["average_runtime_min"] = sum(runtimes) / len(runtimes) / 60

        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
        all_metrics = {}
        for exp in self.experiments_data:
            for metric, value in exp["metrics"].items():
                if isinstance(value, int | float):
                    if metric not in all_metrics:
                        all_metrics[metric] = []
                    all_metrics[metric].append(value)

        # –°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
        for metric, values in all_metrics.items():
            if values:
                stats["metrics_summary"][metric] = {
                    "mean": np.mean(values),
                    "std": np.std(values),
                    "min": np.min(values),
                    "max": np.max(values),
                    "count": len(values),
                }

        # –õ—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç (–ø–æ accuracy –µ—Å–ª–∏ –µ—Å—Ç—å)
        accuracy_metrics = [m for m in all_metrics.keys() if "accuracy" in m.lower()]
        if accuracy_metrics:
            best_metric = accuracy_metrics[0]
            best_exp = max(
                self.experiments_data, key=lambda x: x["metrics"].get(best_metric, 0)
            )
            stats["best_experiment"] = {
                "name": best_exp["name"],
                "task_id": best_exp["task_id"],
                "best_metric": best_metric,
                "best_value": best_exp["metrics"].get(best_metric, 0),
            }

        return stats

    def _generate_html_report(
        self,
        df: pd.DataFrame,
        stats: dict[str, Any],
        metrics_plot: str,
        runtime_plot: str,
        performance_matrix: str,
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç."""
        html_template = f"""
        <!DOCTYPE html>
        <html lang="ru">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>–û—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ - {self.project_name}</title>
            <style>
                body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                h1, h2 {{ color: #333; border-bottom: 2px solid #4CAF50; padding-bottom: 10px; }}
                .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
                .stat-card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; text-align: center; }}
                .stat-value {{ font-size: 2em; font-weight: bold; }}
                .stat-label {{ font-size: 0.9em; opacity: 0.9; }}
                table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
                th {{ background-color: #4CAF50; color: white; }}
                tr:nth-child(even) {{ background-color: #f2f2f2; }}
                .image-container {{ text-align: center; margin: 20px 0; }}
                .image-container img {{ max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }}
                .best-experiment {{ background-color: #e8f5e8; padding: 15px; border-radius: 8px; margin: 20px 0; border-left: 5px solid #4CAF50; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>üî¨ –û—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤</h1>
                <p><strong>–ü—Ä–æ–µ–∫—Ç:</strong> {self.project_name}</p>
                <p><strong>–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>

                <h2>üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h2>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-value">{stats.get('total_experiments', 0)}</div>
                        <div class="stat-label">–í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{stats.get('completed_experiments', 0)}</div>
                        <div class="stat-label">–ó–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{stats.get('average_runtime_min', 0):.1f}</div>
                        <div class="stat-label">–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è (–º–∏–Ω)</div>
                    </div>
                </div>
        """

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ
        if stats.get("best_experiment"):
            best = stats["best_experiment"]
            html_template += f"""
                <div class="best-experiment">
                    <h3>üèÜ –õ—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç</h3>
                    <p><strong>–ù–∞–∑–≤–∞–Ω–∏–µ:</strong> {best['name']}</p>
                    <p><strong>–ú–µ—Ç—Ä–∏–∫–∞:</strong> {best['best_metric']} = {best['best_value']:.4f}</p>
                    <p><strong>Task ID:</strong> {best['task_id']}</p>
                </div>
            """

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        if metrics_plot:
            html_template += f"""
                <h2>üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫</h2>
                <div class="image-container">
                    <img src="{Path(metrics_plot).name}" alt="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫">
                </div>
            """

        if runtime_plot:
            html_template += f"""
                <h2>‚è±Ô∏è –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è</h2>
                <div class="image-container">
                    <img src="{Path(runtime_plot).name}" alt="–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è">
                </div>
            """

        if performance_matrix:
            html_template += f"""
                <h2>üéØ –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</h2>
                <div class="image-container">
                    <img src="{Path(performance_matrix).name}" alt="–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏">
                </div>
            """

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–∞–Ω–Ω—ã—Ö
        if not df.empty:
            html_template += f"""
                <h2>üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</h2>
                {df.to_html(classes='table', escape=False, index=False)}
            """

        html_template += """
            </div>
        </body>
        </html>
        """

        return html_template


def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤."""
    try:
        logger.info("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ ClearML")

        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comparison = ExperimentComparison("ResearchHub")

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        experiments = comparison.collect_experiments_data(limit=10)

        if not experiments:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            logger.info("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:")
            logger.info("python clearml/experiments/experiment_runner.py")
            return

        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        df = comparison.create_metrics_comparison_table()
        print("\n" + "=" * 80)
        print("–¢–ê–ë–õ–ò–¶–ê –°–†–ê–í–ù–ï–ù–ò–Ø –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í")
        print("=" * 80)
        print(df.to_string(index=False))

        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        print("\n" + "=" * 80)
        print("–°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô")
        print("=" * 80)

        metrics_plot = comparison.plot_metrics_comparison()
        if metrics_plot:
            print(f"‚úì –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {metrics_plot}")

        runtime_plot = comparison.plot_runtime_analysis()
        if runtime_plot:
            print(f"‚úì –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {runtime_plot}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")


if __name__ == "__main__":
    main()
