#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ ClearML –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–æ–≤ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
"""

import json
import logging
import time
from datetime import datetime
from pathlib import Path

import requests
from clearml import Task

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("pipeline_monitor.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class ClearMLMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã ClearML."""

    def __init__(self, project_name: str = "ResearchHub"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∞.

        Args:
            project_name: –ò–º—è –ø—Ä–æ–µ–∫—Ç–∞ ClearML
        """
        self.project_name = project_name
        self.servers = {
            "api_server": "http://localhost:8008",
            "web_server": "http://localhost:8080",
            "files_server": "http://localhost:8081",
        }
        self.metrics_file = Path("pipeline_metrics.json")

    def check_servers_health(self) -> dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ClearML —Å–µ—Ä–≤–µ—Ä–æ–≤."""
        logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ ClearML —Å–µ—Ä–≤–µ—Ä–æ–≤...")

        health_status = {}

        for server_name, server_url in self.servers.items():
            try:
                if "8080" in server_url:
                    response = requests.get(server_url, timeout=10)
                else:
                    response = requests.get(f"{server_url}/debug.ping", timeout=10)
                # 200 = OK, 401 = requires auth (server is running)
                health_status[server_name] = response.status_code in (200, 401)

                status_icon = "‚úÖ" if health_status[server_name] else "‚ùå"
                auth_note = " (auth)" if response.status_code == 401 else ""
                logger.info(f"{status_icon} {server_name}: {server_url}{auth_note}")

            except Exception as e:
                health_status[server_name] = False
                logger.error(f"‚ùå {server_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

        return health_status

    def get_pipeline_statistics(self) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ –ø—Ä–æ–µ–∫—Ç–∞
            tasks = Task.get_tasks(
                project_name=self.project_name,
                task_filter={"status": ["completed", "failed", "stopped", "running"]},
            )

            stats = {
                "total_tasks": len(tasks),
                "completed": 0,
                "failed": 0,
                "running": 0,
                "stopped": 0,
                "success_rate": 0,
                "timestamp": datetime.now().isoformat(),
            }

            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç—É—Å–æ–≤
            for task in tasks:
                status = task.get_status()
                if status in stats:
                    stats[status] += 1

            # –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
            if stats["total_tasks"] > 0:
                success_rate = stats["completed"] / stats["total_tasks"] * 100
                stats["success_rate"] = round(success_rate, 2)

            logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤: {stats}")
            return stats

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

    def save_metrics(self, health_status: dict[str, bool], pipeline_stats: dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            existing_metrics = []
            if self.metrics_file.exists():
                with open(self.metrics_file, encoding="utf-8") as f:
                    existing_metrics = json.load(f)

            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            new_metric = {
                "timestamp": datetime.now().isoformat(),
                "servers_health": health_status,
                "pipeline_stats": pipeline_stats,
            }
            existing_metrics.append(new_metric)

            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π
            existing_metrics = existing_metrics[-50:]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            with open(self.metrics_file, "w", encoding="utf-8") as f:
                json.dump(existing_metrics, f, indent=2, ensure_ascii=False)

            logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.metrics_file}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")

    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã."""
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        health_status = self.check_servers_health()
        pipeline_stats = self.get_pipeline_statistics()

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report_lines = [
            "=" * 60,
            "–û–¢–ß–ï–¢ –û –°–û–°–¢–û–Ø–ù–ò–ò –°–ò–°–¢–ï–ú–´ CLEARML",
            "=" * 60,
            f"–í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "üñ•Ô∏è  –°–û–°–¢–û–Ø–ù–ò–ï –°–ï–†–í–ï–†–û–í:",
        ]

        for server, status in health_status.items():
            icon = "‚úÖ" if status else "‚ùå"
            status_text = "OK" if status else "–ù–ï–î–û–°–¢–£–ü–ï–ù"
            report_lines.append(f"   {icon} {server}: {status_text}")

        report_lines.append("")

        if pipeline_stats:
            report_lines.extend(
                [
                    "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–ô–ü–õ–ê–ô–ù–û–í:",
                    f"   –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {pipeline_stats.get('total_tasks', 0)}",
                    f"   –ó–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ: {pipeline_stats.get('completed', 0)}",
                    f"   –û—à–∏–±–∫–∏: {pipeline_stats.get('failed', 0)}",
                    f"   –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è: {pipeline_stats.get('running', 0)}",
                    f"   –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {pipeline_stats.get('stopped', 0)}",
                    f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {pipeline_stats.get('success_rate', 0)}%",
                    "",
                ]
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = self._get_recommendations(health_status, pipeline_stats)
        report_lines.extend(
            [
                "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
                recommendations,
                "=" * 60,
            ]
        )

        report_text = "\n".join(report_lines)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = (
            f"reports/health_report_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"
        )
        Path(report_file).parent.mkdir(parents=True, exist_ok=True)

        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report_text)

        logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        return report_text

    def _get_recommendations(self, health_status: dict[str, bool], stats: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é —Å–∏—Å—Ç–µ–º—ã."""
        recommendations = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ä–≤–µ—Ä—ã
        failed_servers = [name for name, status in health_status.items() if not status]
        if failed_servers:
            recommendations.append(
                f"   ‚ö†Ô∏è  –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä–≤–µ—Ä—ã: {', '.join(failed_servers)}"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if stats:
            success_rate = stats.get("success_rate", 100)
            if success_rate < 80:
                recommendations.append("   ‚ö†Ô∏è  –ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π")

            running_count = stats.get("running", 0)
            if running_count > 5:
                recommendations.append("   ‚ö†Ô∏è  –ú–Ω–æ–≥–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω—è—é—â–∏—Ö—Å—è –∑–∞–¥–∞—á")

        if not recommendations:
            recommendations.append("   ‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ")

        return "\n".join(recommendations)

    def run_monitoring_cycle(self, interval_minutes: int = 5):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        logger.info(f"–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {interval_minutes} –º–∏–Ω—É—Ç)")

        try:
            while True:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                health_status = self.check_servers_health()
                pipeline_stats = self.get_pipeline_statistics()

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                self.save_metrics(health_status, pipeline_stats)

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –∫–∞–∂–¥—ã–π —á–∞—Å
                if datetime.now().minute == 0:
                    report = self.generate_report()
                    logger.info(f"\n{report}")

                # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                time.sleep(interval_minutes * 60)

        except KeyboardInterrupt:
            logger.info("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
            raise


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import sys

    monitor = ClearMLMonitor("ResearchHub")

    if len(sys.argv) > 1 and sys.argv[1] == "report":
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        report = monitor.generate_report()
        print(report)
    else:
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        monitor.run_monitoring_cycle()


if __name__ == "__main__":
    main()
