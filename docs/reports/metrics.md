# Метрики экспериментов

Детальный анализ метрик ML экспериментов.

## Используемые метрики

### Классификационные метрики

| Метрика | Формула | Описание |
|---------|---------|----------|
| **Accuracy** | (TP+TN) / Total | Общая точность |
| **Precision** | TP / (TP+FP) | Точность положительных предсказаний |
| **Recall** | TP / (TP+FN) | Полнота (чувствительность) |
| **F1-score** | 2×P×R / (P+R) | Гармоническое среднее P и R |

### Дополнительные метрики

- **CV Accuracy** — средняя точность на кросс-валидации
- **CV Std** — стандартное отклонение на кросс-валидации
- **Training Time** — время обучения модели

## Сводная таблица метрик

### Все эксперименты

| Эксперимент | Accuracy | Precision | Recall | F1 | CV Mean | CV Std |
|-------------|----------|-----------|--------|-----|---------|--------|
| RF_baseline | 0.275 | 0.285 | 0.275 | 0.165 | 0.320 | 0.041 |
| RF_more_trees | 0.300 | 0.310 | 0.300 | 0.185 | 0.350 | 0.038 |
| RF_deeper | 0.275 | 0.290 | 0.275 | 0.170 | 0.325 | 0.043 |
| RF_conservative | 0.250 | 0.260 | 0.250 | 0.145 | 0.300 | 0.048 |
| **RF_more_features** | **0.350** | **0.365** | **0.350** | **0.205** | **0.400** | 0.031 |
| RF_unigrams_only | 0.225 | 0.235 | 0.225 | 0.130 | 0.275 | 0.052 |
| SVM_baseline | 0.225 | 0.240 | 0.225 | 0.160 | 0.280 | 0.055 |
| SVM_linear | 0.250 | 0.265 | 0.250 | 0.180 | 0.320 | 0.045 |
| SVM_high_C | 0.225 | 0.235 | 0.225 | 0.155 | 0.285 | 0.050 |
| SVM_low_C | 0.200 | 0.210 | 0.200 | 0.140 | 0.260 | 0.058 |
| SVM_poly | 0.200 | 0.215 | 0.200 | 0.135 | 0.250 | 0.062 |
| LR_baseline | 0.200 | 0.215 | 0.200 | 0.150 | 0.280 | 0.052 |
| LR_l1_penalty | 0.200 | 0.210 | 0.200 | 0.145 | 0.275 | 0.054 |
| LR_high_reg | 0.175 | 0.185 | 0.175 | 0.120 | 0.240 | 0.065 |
| LR_low_reg | 0.200 | 0.215 | 0.200 | 0.145 | 0.275 | 0.055 |
| LR_lbfgs | 0.200 | 0.215 | 0.200 | 0.150 | 0.280 | 0.052 |
| LR_extended_ngrams | 0.200 | 0.210 | 0.200 | 0.140 | 0.270 | 0.058 |

## Анализ по алгоритмам

### Random Forest

```
Accuracy:    ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░ 27.5% (avg)
F1-score:    ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░ 16.5% (avg)
CV Accuracy: ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░ 33.0% (avg)
```

| Статистика | Значение |
|------------|----------|
| Лучший результат | RF_more_features (35%) |
| Худший результат | RF_unigrams_only (22.5%) |
| Среднее | 27.5% |
| Медиана | 27.5% |
| Разброс (std) | 4.2% |

### SVM

```
Accuracy:    ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░ 22.0% (avg)
F1-score:    ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░░ 15.4% (avg)
CV Accuracy: ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░ 28.0% (avg)
```

| Статистика | Значение |
|------------|----------|
| Лучший результат | SVM_linear (25%) |
| Худший результат | SVM_poly (20%) |
| Среднее | 22.0% |
| Медиана | 22.5% |
| Разброс (std) | 2.2% |

### Logistic Regression

```
Accuracy:    ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░ 19.6% (avg)
F1-score:    ▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░░░ 14.2% (avg)
CV Accuracy: ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░ 26.3% (avg)
```

| Статистика | Значение |
|------------|----------|
| Лучший результат | LR_baseline (20%) |
| Худший результат | LR_high_reg (17.5%) |
| Среднее | 19.6% |
| Медиана | 20.0% |
| Разброс (std) | 0.9% |

## Корреляция метрик

### Accuracy vs F1-score

```
F1-score
    ^
0.22|                              *
0.20|                         *
0.18|                    *
0.16|               *
0.14|          *
0.12|     *
    +----------------------------> Accuracy
      0.17  0.20  0.25  0.30  0.35
```

Корреляция: **r = 0.95** (сильная положительная)

### CV Accuracy vs Test Accuracy

```
Test Accuracy
    ^
0.35|                              *
0.30|                    *    *
0.25|              *  *
0.20|    *    *  *
0.18|  *  *
    +----------------------------> CV Accuracy
      0.24  0.28  0.32  0.36  0.40
```

Корреляция: **r = 0.92** (сильная положительная)

## Время обучения

### По экспериментам

| Эксперимент | Время (сек) | % от макс. |
|-------------|-------------|------------|
| LR_baseline | 0.45 | █░░░░░░░░░ 11% |
| LR_l1_penalty | 0.52 | █░░░░░░░░░ 13% |
| SVM_linear | 0.85 | ██░░░░░░░░ 21% |
| SVM_baseline | 1.20 | ███░░░░░░░ 30% |
| RF_conservative | 1.85 | ████░░░░░░ 46% |
| RF_baseline | 2.45 | ██████░░░░ 61% |
| RF_more_trees | 3.85 | █████████░ 96% |
| RF_more_features | 4.00 | ██████████ 100% |

### Соотношение качество/время

```
Эффективность (Accuracy / Time):

LR_baseline:     ██████████████████████████████████ 0.44
SVM_linear:      ██████████████████████████████ 0.29
RF_baseline:     █████████████ 0.11
RF_more_features: ██████████ 0.09
```

## Анализ гиперпараметров

### Random Forest: n_estimators

| n_estimators | Accuracy | Время (сек) |
|--------------|----------|-------------|
| 50 | 0.250 | 1.85 |
| 100 | 0.275 | 2.45 |
| 200 | 0.300 | 3.85 |

**Вывод**: Увеличение числа деревьев улучшает качество, но увеличивает время.

### Random Forest: max_depth

| max_depth | Accuracy | F1 |
|-----------|----------|-----|
| 5 | 0.250 | 0.145 |
| 10 | 0.275 | 0.165 |
| 20 | 0.275 | 0.170 |

**Вывод**: Глубина больше 10 не даёт существенного улучшения.

### SVM: C

| C | Accuracy | F1 |
|---|----------|-----|
| 0.1 | 0.200 | 0.140 |
| 1.0 | 0.250 | 0.180 |
| 10.0 | 0.225 | 0.155 |

**Вывод**: C=1.0 оптимально, слишком высокие/низкие значения ухудшают качество.

## Confusion Matrix (лучшая модель)

### RF_more_features

```
              Predicted
           cs.CV  eess.IV  q-bio.QM
Actual
cs.CV        8       2        2
eess.IV      3       5        2
q-bio.QM     2       3        3

Accuracy: 35% (16/46)
```

### Метрики по классам

| Класс | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| cs.CV | 0.62 | 0.67 | 0.64 | 12 |
| eess.IV | 0.50 | 0.50 | 0.50 | 10 |
| q-bio.QM | 0.43 | 0.38 | 0.40 | 8 |

## Выводы

### Ключевые наблюдения

1. **Низкая точность** (~35% max) объясняется:
   - Малым объёмом данных (~100 записей)
   - Близостью категорий (все связаны с обработкой изображений)
   - Сложностью NLP задачи

2. **Random Forest лидирует** благодаря:
   - Устойчивости к переобучению
   - Способности улавливать нелинейные зависимости
   - Работе с высокоразмерными TF-IDF признаками

3. **Feature engineering важен**:
   - Увеличение словаря с 5000 до 10000 дало +7.5% accuracy
   - Триграммы важнее, чем 4-граммы

### Рекомендации

!!! tip "Для улучшения метрик"

    1. Увеличить объём данных (x10)
    2. Использовать предобученные модели (BERT)
    3. Добавить метаданные как признаки
    4. Попробовать ensemble методы
