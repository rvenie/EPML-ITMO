# Инструкция по воспроизводимости

Данная инструкция содержит пошаговое руководство для полного воспроизведения результатов системы версионирования данных и моделей.


### Шаг 1: Клонирование и установка зависимостей

```bash
# Клонируем репозиторий
git clone <адрес_репозитория>
cd research_agets_hub

# Переключаемся на правильную ветку
git checkout feature/setup-dvc-mlflow

# Создаем виртуальное окружение
python -m venv venv
source venv/bin/activate  # На Windows: venv\Scripts\activate

# Устанавливаем зависимости
pip install -r requirements.txt
```

**Ожидаемый результат:** Успешная установка всех пакетов без ошибок.

### Шаг 2: Инициализация DVC

```bash
# DVC уже инициализирован, настраиваем remote storage
mkdir -p ../dvc-storage
dvc remote add -d local_storage ../dvc-storage

# Проверяем конфигурацию DVC
dvc remote list
```

**Ожидаемый результат:**
```
local_storage	../dvc-storage
```

### Шаг 3: Запуск MLflow сервера

```bash
# Запускаем MLflow сервер в фоне
nohup mlflow server --host 127.0.0.1 --port 3000 --backend-store-uri file:./mlruns > mlflow.log 2>&1 &

# Ждем несколько секунд для запуска
sleep 5

# Проверяем доступность сервера
curl -s http://127.0.0.1:3000/ | head -1
```

**Ожидаемый результат:** HTML-ответ, начинающийся с `<!doctype html>`

### Шаг 4: Воспроизведение обработки данных

```bash
# Запускаем предобработку данных
python scripts/preprocess_data.py
```

**Ожидаемый результат:**
```
2025-11-30 16:45:51,617 - INFO - Final dataset shape: (51, 21)
2025-11-30 16:45:51,618 - INFO - Data preprocessing completed successfully!
```

Должны быть созданы файлы:
- `data/processed/publications_processed.csv` (51 запись, 21 столбец)
- `data/processed/processing_metadata.yaml`

### Шаг 5: Обучение модели

```bash
# Запускаем обучение модели с MLflow логированием
python scripts/train_model.py \
    --input data/processed/publications_processed.csv \
    --model-output models/classifier.pkl \
    --metrics metrics.json
```

**Ожидаемые результаты:**
```
2025-11-30 16:46:13,132 - INFO - Cross-validation scores: [0.71428571 0.84615385 0.76923077]
2025-11-30 16:46:13,132 - INFO - Mean CV score: 0.7766 (+/- 0.1082)
Successfully registered model 'research_publications_classification_model'.
Created version '1' of model 'research_publications_classification_model'.
```

## Проверка результатов

### Проверка метрик модели
```bash
# Просматриваем итоговые метрики
cat metrics.json
```

**Ожидаемые значения:**
- test_accuracy: ~0.91 (90.9%)
- test_f1_score: ~0.87 (86.8%)
- cv_mean: ~0.78 (77.7%)

### Проверка DVC статуса
```bash
# Проверяем статус версионирования
dvc status
```

**Ожидаемый результат:** `Data and pipelines are up to date.`

### Проверка MLflow
```bash
# Открываем MLflow UI в браузере
echo "Откройте в браузере: http://127.0.0.1:5000"

```

### Проверка созданных файлов
```bash
# Проверяем структуру файлов
ls -la data/raw/*.dvc data/processed/*.dvc models/*.dvc
```

**Ожидаемые файлы:**
- `data/raw/publications.csv.dvc`
- `data/raw/data_metadata.yaml.dvc`
- `data/processed/publications_processed.csv.dvc`
- `data/processed/processing_metadata.yaml.dvc`
- `models/classifier.pkl.dvc`

## Альтернативный способ: воспроизведение через Docker

### Вариант 1: Использование Docker Compose
```bash
# Запуск MLflow сервера
docker-compose up -d mlflow-server

# Обучение модели в контейнере
docker-compose run --rm ml-app train

# Доступ к MLflow UI
echo "MLflow UI: http://localhost:3000"
```

### Вариант 2: Ручная сборка Docker образа
```bash
# Сборка образа
docker build -t ml-versioning .

# Запуск предобработки
docker run --rm -v $(pwd)/data:/app/data ml-versioning preprocess

# Запуск обучения
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/mlruns:/app/mlruns \
  ml-versioning train
```

При возникновении проблем, не описанных в данной инструкции, проверьте логи в файлах `mlflow.log`, `preprocessing.log`, `training.log`.
